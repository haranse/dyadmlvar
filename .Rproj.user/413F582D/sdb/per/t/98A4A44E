{
    "collab_server" : "",
    "contents" : "#install the packages if they are missing\nlist.of.packages <- c(\"glmnet\", \"mlVAR\")\nnew.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n#upload packages\nlibrary(glmnet)\nlibrary(mlVAR)\n\n#function that analyzes network into strength and density variables. Assumes variables are list for one subject and then equivalent list for another\nread_network <- function(mlvar_model) {\n  ntwrk_vars <- list()\n  ntwrk_vars$contemp <- list()\n  ntwrk_vars$temporal <- list()\n\n\n  #calculate node strength, as mean edge strength. Temporal node strength includes edges in both directions\n  ntwrk_vars$contemp$strength <- rowMeans(abs(mlvar_model$results$Theta$cor$mean))-(1/length(mlvar_model$results$Theta$cor$mean[1,]))\n  ntwrk_vars$temporal$strength <- rowMeans(abs(mlvar_model$results$Beta$mean))\n\n  ntwrk_vars$vars <- list()\n  ntwrk_vars$vars$names <- mlvar_model$input$vars\n  ntwrk_vars$vars$len <- length(ntwrk_vars$vars$names)\n\n  #getting couple-level indices\n  ntwrk_vars$vars$num <-length(mlvar_model$results$Beta$subject[[1]])\n  ntwrk_vars$temporal$all <- data.frame(matrix(nrow=0,ncol=ntwrk_vars$vars$num+1+sqrt(ntwrk_vars$vars$num)*2+3))\n  ntwrk_vars$contemp$all <- data.frame(matrix(nrow=0,ncol=(ntwrk_vars$vars$num-sqrt(ntwrk_vars$vars$num))/2+3))\n\n  for (i in 1:length(mlvar_model$IDs))\n  #i = 1\n     {\n       temporal.1 <- mlvar_model$results$Beta$subject[[i]]\n       dim(temporal.1)<-NULL\n       temporal.1<-data.frame(temporal.1)\n       temporal.1<-as.data.frame(t(temporal.1))\n\n       #calculate strength either for connections to each node or from each node\n\n       for (t in 1:(ntwrk_vars$vars$len)){\n         temporal.1[[paste(ntwrk_vars$vars$names[[t]],\" temp.to. centrality\",sep=\"\")]] <- rowMeans(abs(mlvar_model$results$Beta$subject[[i]]))[t]\n         temporal.1[[paste(ntwrk_vars$vars$names[[t]],\" temp.from. centrality\",sep=\"\")]] <- colMeans(abs(mlvar_model$results$Beta$subject[[i]]))[t]\n       }\n\n       #calculate per person density\n       temporal.1.1<-data.frame(mlvar_model$results$Beta$subject[[i]])\n       a<-mean(as.matrix((abs(temporal.1.1[1:(ntwrk_vars$vars$len/2),1:(ntwrk_vars$vars$len/2)]))))\n       b<-mean(as.matrix((abs(temporal.1.1[(ntwrk_vars$vars$len/2+1):ntwrk_vars$vars$len,(ntwrk_vars$vars$len/2+1):ntwrk_vars$vars$len]))))\n       c<-mean(as.matrix((abs(temporal.1.1[(ntwrk_vars$vars$len/2+1):ntwrk_vars$vars$len,1:(ntwrk_vars$vars$len/2)]))))\n       d<-mean(as.matrix((abs(temporal.1.1[1:(ntwrk_vars$vars$len/2),(ntwrk_vars$vars$len/2+1):ntwrk_vars$vars$len]))))\n\n       #intra density - connections in both directions between couple member's variables to themselves\n       temporal.1$temporal.intra.density<-mean(c(a,b))\n\n       #inter density - connections in both directions between couple member's variables to themselves\n       temporal.1$temporal.inter.density<-mean(c(c,d))\n\n       #ratio between intra and inter density\n       temporal.1$temporal.ratio.density<-with(temporal.1,temporal.intra.density/temporal.inter.density)\n       temporal.1$ID<-mlvar_model$IDs[i]\n       ntwrk_vars$temporal$all<-rbind( ntwrk_vars$temporal$all,temporal.1)\n\n\n       #Contemporaneous matrix is symmetrical - serializing half of it to avoid repetition of each edge twice\n       contemporaneous.1 <- mlvar_model$results$Theta$pcor$subject[[i]]\n       contemporaneous.2<-NULL\n       for (t in 1:(ntwrk_vars$vars$len-1)){\n         contemporaneous.2<-c(contemporaneous.2,contemporaneous.1[t,(t+1):ntwrk_vars$vars$len])\n                                        }\n       contemporaneous.2<-data.frame(t(contemporaneous.2))\n       for (t in 1:(ntwrk_vars$vars$len)){\n         contemporaneous.2[[paste(ntwrk_vars$vars$names[[t]],\" cont. centrality\",sep=\"\")]] <- rowMeans(abs(mlvar_model$results$Theta$pcor$subject[[i]]))[t]-(1/length(mlvar_model$results$Theta$pcor$subject[[i]][1,]))\n       }\n\n       #caluculating inter and intra density\n       cont.1<-data.frame(mlvar_model$results$Theta$pcor$subject[[i]])\n       a<-sum(as.matrix((abs(cont.1[1:(ntwrk_vars$vars$len/2),1:(ntwrk_vars$vars$len/2)]))))\n       a<-(a-(ntwrk_vars$vars$len/2))/((ntwrk_vars$vars$len/2)^2-(ntwrk_vars$vars$len/2))\n       b<-sum(as.matrix((abs(cont.1[(ntwrk_vars$vars$len/2+1):ntwrk_vars$vars$len,(ntwrk_vars$vars$len/2+1):ntwrk_vars$vars$len]))))\n       b<-(b-(ntwrk_vars$vars$len/2))/((ntwrk_vars$vars$len/2)^2-(ntwrk_vars$vars$len/2))\n       c<-mean(as.matrix((abs(cont.1[(ntwrk_vars$vars$len/2+1):ntwrk_vars$vars$len,1:(ntwrk_vars$vars$len/2)]))))\n       contemporaneous.2$cont.intra.density<-mean(c(a,b))\n       contemporaneous.2$cont.inter.density<-c\n       contemporaneous.2$cont.ratio.density<-with(contemporaneous.2,cont.intra.density/cont.inter.density)\n       contemporaneous.2$ID<-mlvar_model$IDs[i]\n       ntwrk_vars$contemp$all<-rbind(ntwrk_vars$contemp$all,contemporaneous.2)\n\n  }\n\n  #generate names for couple level variables\n  ntwrk_vars$temporal$names <- vector()\n  ntwrk_vars$temporal$centrality_names <- list()\n  ntwrk_vars$temporal$inter_names <- vector()\n  ntwrk_vars$temporal$intra_men_names <- vector()\n  ntwrk_vars$temporal$intra_women_names <- vector()\n  ntwrk_vars$temporal$intra_names <- vector()\n  ntwrk_vars$temporal$density_names<-c(\"temporal.intra.density\",\"temporal.inter.density\",\"temporal.ratio.density\")\n  for(i in 1:ntwrk_vars$vars$len){\n    for (j in 1:ntwrk_vars$vars$len)\n    {\n      ntwrk_vars$temporal$names[[(i-1)*ntwrk_vars$vars$len + j]]<-paste(ntwrk_vars$vars$names[[i]],\"->\",ntwrk_vars$vars$names[[j]])\n    }\n  }\n  names(ntwrk_vars$temporal$all)[1:ntwrk_vars$vars$len^2] <- ntwrk_vars$temporal$names\n\n  for (i in 1:length(var.names)){\n    ntwrk_vars$temporal$centrality_names[[i*2 - 1]]<- paste(ntwrk_vars$vars$names[[i]],\" temp.to. centrality\",sep=\"\")\n    ntwrk_vars$temporal$centrality_names[[i*2]]<- paste(ntwrk_vars$vars$names[[i]],\" temp.from. centrality\",sep=\"\")\n  }\n  half.len<-ntwrk_vars$vars$len/2\n  for(i in 1:half.len){\n    for (j in 1:half.len)\n    {\n      ntwrk_vars$temporal$intra_men_names[[(i-1)*half.len + j]]<-paste(ntwrk_vars$vars$names[[i]],\"->\",ntwrk_vars$vars$names[[j]])\n      ntwrk_vars$temporal$inter_names[[(i-1)*half.len + j]]<-paste(ntwrk_vars$vars$names[[i]],\"->\",ntwrk_vars$vars$names[[j+half.len]])\n    }\n\n  }\n\n  for(i in 1:half.len){\n  for (j in 1:half.len)\n  {\n    ntwrk_vars$temporal$intra_women_names[[(i-1)*half.len + j]]<-paste(ntwrk_vars$vars$names[[i+half.len]],\"->\",ntwrk_vars$vars$names[[j+half.len]])\n    ntwrk_vars$temporal$inter_names[[half.len^2 +(i-1)*half.len + j]]<-paste(ntwrk_vars$vars$names[[i+half.len]],\"->\",ntwrk_vars$vars$names[[j]])\n  }\n  }\n  ntwrk_vars$temporal$intra_names<-c(ntwrk_vars$temporal$intra_men_names,ntwrk_vars$temporal$intra_women_names)\n\n  ntwrk_vars$contemp$names <- vector()\n  ntwrk_vars$contemp$centrality_names <- list()\n  ntwrk_vars$contemp$inter_names <- vector()\n  ntwrk_vars$contemp$intra_names <- vector()\n  ntwrk_vars$contemp$intra_men_names <- vector()\n  ntwrk_vars$contemp$intra_women_names <- vector()\n  ntwrk_vars$contemp$density_names<-c(\"cont.intra.density\",\"cont.inter.density\",\"cont.ratio.density\")\n  for(i in 1:(ntwrk_vars$vars$len-1)){\n    for (j in (i+1):ntwrk_vars$vars$len)\n    {\n      ntwrk_vars$contemp$names[(length(ntwrk_vars$contemp$names)+1)]<-paste(ntwrk_vars$vars$names[[i]],\"<->\",ntwrk_vars$vars$names[[j]])\n    }\n  }\n  names(ntwrk_vars$contemp$all)[1:length(ntwrk_vars$contemp$names)]<-ntwrk_vars$contemp$names\n\n  for (i in 1:length(ntwrk_vars$vars$names)){\n    ntwrk_vars$contemp$centrality_names[i]<- paste(ntwrk_vars$vars$names[[i]],\" cont. centrality\",sep=\"\")\n  }\n\n  for(i in 1:(half.len-1)){\n    for (j in (i+1):half.len)\n    {\n      ntwrk_vars$contemp$intra_men_names[[length(ntwrk_vars$contemp$intra_men_names)+1]]<-paste(ntwrk_vars$vars$names[[i]],\"<->\",ntwrk_vars$vars$names[[j]])\n      ntwrk_vars$contemp$intra_women_names[[length(ntwrk_vars$contemp$intra_women_names)+1]]<-paste(ntwrk_vars$vars$names[[i+half.len]],\"<->\",ntwrk_vars$vars$names[[j+half.len]])\n          }\n\n  }\n  ntwrk_vars$contemp$intra_names<-c(ntwrk_vars$contemp$intra_men_names,ntwrk_vars$contemp$intra_women_names)\n  for(i in 1:(half.len)){\n    for (j in (half.len+1):(half.len*2))\n    {\n      ntwrk_vars$contemp$inter_names[[length(ntwrk_vars$contemp$inter_names)+1]]<-paste(ntwrk_vars$vars$names[[i]],\"<->\",ntwrk_vars$vars$names[[j]])\n\n    }\n\n\n  }\n\n  return(ntwrk_vars)\n}\n\nlasso<-function(Data,Predictors,Outcome,Seeds=1,Train=F,PropOfTrain=.75){\n  #Data=all,Predictors=pre_inter,Outcome=\"W_csi_3_resid_1\",Train=F,PropOfTrain=.75)\n  all.2<-Data[,c(Predictors,Outcome)]\n  #removing incomplete data;\n  all.2<-na.omit(all.2)\n  #standardized data- #see here for more info: https://stats.stackexchange.com/questions/126109/coefficient-value-from-glmnet\n  #and here https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html\n  all.2<-as.data.frame(scale(all.2,center=T,scale = T))\n  #taking out edges without variability\n  for (no.var in Predictors){\n    #no.var<-Predictors[9]\n    print(paste(no.var,\":\",is.na(var(all.2[,no.var]))))\n    print(var(all.2[,no.var]))\n    if (is.na(var(all.2[,no.var]))){\n      all.2<-all.2[,-which(names(all.2)==no.var)]\n        }\n  }\n  #transforming into a matrix\n  x<-model.matrix (all.2[,Outcome]~.,all.2)[,-1]\n  x<-x[,-(length(x[1,]))]\n  y<-as.matrix(all.2[,Outcome])\n  #If  train=F then no splitting of data occurs, otherwise data is splitted\n  if (Train==F){\n    #using cross-validation to choose the tuning parameter; by default it performs ten-fold cross-validation\n    set.seed(Seeds)\n    cv.out<-cv.glmnet(x,y,alpha=1,intercept = F,standardize = F)\n    plot(cv.out)\n    #for plot interpretatin see: https://stats.stackexchange.com/questions/253963/how-to-interpret-cv-glmnet-plot\n    bestlam <-cv.out$lambda.min\n    #getting estimates\n    a<-glmnet(x,y,alpha=1,lambda = bestlam,intercept = F,standardize = F)\n    b<-coefficients(a)\n    b<-b[1:length(b),]\n    b<-(round(b[b!=0],3))\n    #estimate a ranking of variable importance,\n    #i.e., the maximal value of lambda at which\n    #the variable first entered the model was determined\n    d<-as.data.frame(b)\n    names(d)[1]<-\"Est.\"\n    d.2<-rownames(d)\n    for (i in d.2){\n      #i<-d.2[1]\n      e<-as.data.frame(cv.out$glmnet.fit$beta[i,])\n      row.names(e)<-NULL\n      e<-subset(e,e[,1]!=0)\n      d[i,\"Importance\"]<-row.names(e)[1]\n    }\n\n    pred.mat <- cbind(y_true = y, y_pred = predict(a,newx=x)[, 1])\n    Rs <- boot::corr(d=pred.mat) ^ 2\n    c<-list(Estimates=d,Rsquared=Rs)\n    return(c)\n  } else {\n        #splitting into train and test data\n  set.seed(Seeds)\n  train<-sort(sample (1: nrow(x), nrow(x)*PropOfTrain))\n  test<-(-train)\n  y.test<-y[test]\n  #using cross-validation to choose the tuning parameter; by default it performs ten-fold cross-validation\n  #At least 10 observation per fold\n  folds<-floor(length(y[train])/10)\n  set.seed(Seeds)\n  cv.out<-cv.glmnet(x[train,],y[train],alpha=1,intercept = F,standardize = F,nfolds = folds)\n  plot(cv.out)\n  #for plot interpretatin see: https://stats.stackexchange.com/questions/253963/how-to-interpret-cv-glmnet-plot\n  bestlam <-cv.out$lambda.min\n  #getting estimates\n  a<-glmnet(x[train,],y[train],alpha=1,lambda = bestlam,intercept = F,standardize = F)\n  b<-coefficients(a)\n  b<-b[1:length(b),]\n  b<-(round(b[b!=0],3))\n  #estimate a ranking of variable importance,\n  #i.e., the maximal value of lambda at which\n  #the variable first entered the model was determined\n  d<-as.data.frame(b)\n  names(d)[1]<-\"Est.\"\n  d.2<-rownames(d)\n    for (i in d.2){\n    #i<-d.2[1]\n    e<-as.data.frame(cv.out$glmnet.fit$beta[i,])\n    row.names(e)<-NULL\n    e<-subset(e,e[,1]!=0)\n    d[i,\"Importance\"]<-row.names(e)[1]\n  }\n\n  pred.mat <- cbind(y_true = y[test], y_pred = predict(a,newx=x[test,])[, 1])\n  Rs <- boot::corr(d=pred.mat) ^ 2\n  c<-list(Estimates=d,Rsquared=Rs)\n  return(c)\n  }\n}\n",
    "created" : 1543999523581.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3250990965",
    "id" : "98A4A44E",
    "lastKnownWriteTime" : 1543999439,
    "last_content_update" : 1543999439,
    "path" : "D:/Dropbox/Haran/Ongoing Papers/Network paper/dyadmlvar/R/Functions.R",
    "project_path" : "R/Functions.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}